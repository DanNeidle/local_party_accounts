# analyse_candidates.py

import csv
import os
import json
import google.generativeai as genai
import shutil # For file backup

# this lets us look at individual units for testing purposes. "ST0028221" should show no rental income. "ST0028175" should show some, but no tax. 
# or None for running on the full set
debugging_example = None

# --- Configuration ---
try:
    from accounts_secrets import gemini_api_key
    if not gemini_api_key or gemini_api_key == "YOUR_ACTUAL_API_KEY_HERE":
        raise ValueError("API key not set in accounts_secrets.py")
except ImportError:
    print("Error: Could not import gemini_api_key from accounts_secrets.py")
    print("Please ensure the file exists, is in the same directory, and contains your API key.")
    exit(1)
except ValueError as ve:
     print(f"Error: {ve}")
     exit(1)

INPUT_CSV = 'text_search_results.csv' # Input CSV generated by the first script
OUTPUT_CSV = 'analysis_results.csv'   # Output CSV for this script's results
PDF_DIR = 'accounts'
MODEL_NAME = 'gemini-1.5-flash-latest'

# Configure the Google Generative AI client
try:
    genai.configure(api_key=gemini_api_key)
    print(f"Gemini API configured successfully.")
except Exception as e:
    print(f"Error configuring Gemini API: {e}")
    exit(1)

# --- Backup ---
BACKUP_CSV = OUTPUT_CSV + '.old'
try:
    if os.path.exists(OUTPUT_CSV):
        shutil.copy2(OUTPUT_CSV, BACKUP_CSV)
        print(f"Backed up existing results to {BACKUP_CSV}")
except Exception as bk_err:
    print(f"Warning: Could not create backup file. Error: {bk_err}")

# --- Load Already Processed Units ---
processed_units = set()
try:
    with open(OUTPUT_CSV, mode='r', newline='', encoding='utf-8') as f_in:
        reader = csv.DictReader(f_in)
        if 'number' not in reader.fieldnames:
             print(f"Warning: Existing {OUTPUT_CSV} missing 'number' column. Cannot resume accurately.")
        else:
            for row in reader:
                if row.get('number'): # Add unit number to set if present
                    processed_units.add(row['number'])
    print(f"Found {len(processed_units)} units already processed in {OUTPUT_CSV}.")
except FileNotFoundError:
    print(f"No existing {OUTPUT_CSV} found. Starting fresh.")
except Exception as read_err:
    print(f"Error reading existing {OUTPUT_CSV}: {read_err}. Cannot resume accurately.")
    # Decide if we should exit or continue without resuming
    # exit(1) # Option: Exit if resume state is corrupted/unreadable

# --- Count Eligible Candidates for Progress ---
total_eligible_count = 0
candidates_to_process = []
try:
    with open(INPUT_CSV, mode='r', newline='', encoding='utf-8-sig') as csvfile:
        reader = csv.DictReader(csvfile)
        # Use the correct column names from text_search_results.csv
        required_input_cols = ['number', 'rent_pages', 'unit_name', 'entity_name']
        if not all(col in reader.fieldnames for col in required_input_cols):
             # The error message should also reflect the names we are actually checking for
             raise ValueError(f"Input CSV '{INPUT_CSV}' must contain columns: {', '.join(required_input_cols)}")

        for row in reader:
            rent_pages_value = row.get('rent_pages', '').strip()
            unit_number = row.get('number')
            # Check eligibility: has rent pages, has a number, and not already processed
            if unit_number and rent_pages_value and rent_pages_value.lower() != "pdf not found":
                 if unit_number not in processed_units:
                      total_eligible_count += 1
                      # Store the necessary info for the second pass
                      candidates_to_process.append({
                          'number': unit_number,
                          'unit_name': row['unit_name'],      # Ensure this matches required_input_cols
                          'entity_name': row['entity_name'],  # Ensure this matches required_input_cols
                          'rent_pages': rent_pages_value
                      })

except FileNotFoundError:
    print(f"Error: Input CSV file not found - '{INPUT_CSV}'")
    exit(1)
except ValueError as ve: # Catches missing columns error
    print(f"Input CSV Format Error: {ve}")
    exit(1)
except Exception as e:
    print(f"An unexpected error occurred reading {INPUT_CSV}: {e}")
    exit(1)

print(f"Total units eligible for analysis in this run: {total_eligible_count}")

if total_eligible_count == 0 and len(processed_units) > 0:
    print("All eligible units seem to be already processed.")
    exit(0)
elif total_eligible_count == 0:
     print(f"No eligible units found in {INPUT_CSV} that require processing.")
     exit(0)


# --- Define Output CSV Headers ---
output_fieldnames = [
    'number', 'unit_name', 'entity_name', 'success', 'reason', 
    'rental_income', 'tax_paid', 'rented_to_mp', 
    'approx_tax_rate'
]

# --- Helper Function for Safe Float Conversion ---
def safe_float(value):
    """Converts value to float, returns None if conversion fails."""
    if value is None:
        return None
    try:
        return float(value)
    except (ValueError, TypeError):
        return None

# --- Helper Function for Tax Rate Calculation ---
def calculate_tax_rate(tax_raw, income_raw):
    """Calculates approximate tax rate based on raw inputs."""
    income_num = safe_float(income_raw)
    tax_num = safe_float(tax_raw)
    approx_tax_rate = ''  # Default to blank

    if income_num is not None and income_num > 0:
        # Positive income
        if tax_num is not None and tax_num >= 0:
            # Valid, non-negative tax
            approx_tax_rate = tax_num / income_num
        else:
            # Positive income, but tax is missing, invalid, or negative -> Rate is 0
            approx_tax_rate = 0.0
    # else: Income is zero, negative, None, or invalid -> rate remains '' (blank)
    return approx_tax_rate


# --- Main Processing Loop ---
print(f"\nStarting analysis of {total_eligible_count} units...")
current_count = 0

# Open the output file in append mode ('a+'). Create if not exists.
try:
    with open(OUTPUT_CSV, mode='a+', newline='', encoding='utf-8') as outfile:
        writer = csv.DictWriter(outfile, fieldnames=output_fieldnames)

        # Write header only if file is new (or empty)
        outfile.seek(0, os.SEEK_END) # Go to end of file
        if outfile.tell() == 0: # Check if file size is 0
            writer.writeheader()
            print(f"Created new output file {OUTPUT_CSV} with headers.")

        # Iterate through the candidates identified in the first pass
        for candidate in candidates_to_process:
            current_count += 1
            unit_number = candidate['number']
            unit_name = candidate['unit_name']
            entity_name = candidate['entity_name']
            
            if debugging_example and unit_number != debugging_example:
                continue
            
            # Print status update for the current unit
            print(f"\n{unit_number}: {unit_name} ({entity_name}) ({current_count}/{total_eligible_count})")

            pdf_filename = f"{unit_number}.pdf"
            pdf_path = os.path.join(PDF_DIR, pdf_filename)

            # Default result values
            analysis_result = {
                'number': unit_number,
                'unit_name': unit_name,
                'entity_name': entity_name,
                'success': False, # Default to False
                'rental_income': '',
                'tax_paid': '',
                'reason': '',
                'approx_tax_rate': ''
            }
            uploaded_file = None

            # Check if the PDF file actually exists (redundant check if pre-filtered, but safe)
            if not os.path.exists(pdf_path):
                print(f"  Error: PDF file not found at '{pdf_path}'. Skipping.")
                analysis_result['success'] = False
                analysis_result['reason'] = "PDF file not found"
                writer.writerow(analysis_result) # Write failure row
                continue # Move to next candidate

            try:
                # --- 1. Upload File ---
                # print(f"  Uploading PDF: '{pdf_path}'...")
                uploaded_file = genai.upload_file(path=pdf_path, display_name=pdf_filename)
                # print(f"  Successfully uploaded: {uploaded_file.name}")

                # --- 2. Call Gemini API ---
                print(f"  Sending request to Gemini model ({MODEL_NAME})...")
                model = genai.GenerativeModel(MODEL_NAME)
                prompt = """Please analyse the attached PDF document containing the accounts of a local political party. My goal is to check whether it is paying the correct corporation tax on rental income.

Specifically, look for mentions and figures related to:
1.  Income received from renting out property ("rental_income"). Look for line items explicitly labelled 'Property and rental income' or similar. **Ensure the figure extracted is directly associated with this specific label on the same line or in the correct column within a table.** Pay close attention to table structures.
2.  Tax paid by the party, particularly Corporation Tax if mentioned ("tax_paid").

Please be careful *not* to extract figures for rent the party *paid* (rental expenses). Focus only on income received from rent and tax the party paid out. **Crucially, do not attribute figures from other income lines (like 'Donations' or 'Transfers in') to 'rental_income'.**
Also be careful not to extract the numbers of notes. For example it's common to see something like this:

Income
Membership 1 4107.53 5610.88
Affiliations 2
Donations 3 14518.92 8805.00
Branch Income 4
Fundraising income 5 8809.70 7553514
Investment income 6
Transfers in 7 8202.09 3400.00
Property and rental 8
income/Office services
Miscellaneous 9
Total income 35638 .24 2536902

Here the 8 is a note not an amount of income. If we read through the PDF to note 8 you can see a breakdown of the rental income - there is none.

Also be careful not to return tax which relates to employees. This might be under "salary costs" or "income tax". 

Respond ONLY with a valid JSON object containing the following keys:
- "rental_income": The figure found **specifically and directly associated with the rental income line item**. Use a number, 0 if zero is stated, or **null if the rental income line item exists but its corresponding figure is missing, blank, or not applicable.**
- "tax_paid": The figure found for tax paid (use a number, 0 if zero is stated, or null if not found/mentioned). Look for Corporation Tax specifically if possible, but include any general tax paid figure if CT isn't itemised.
- "rented_to_mp": this should be True if the accounts show that the rental income is from space rented to the local MP. If it doesn't, or you can't identify who it's rented to, set to False
- "success": Set to true if you could successfully analyse the document for these items, even if figures were not found (i.e., result is null). Set to false only if you encountered an error reading the PDF or understanding the request.
- "reason": If "success" is false, provide a brief reason for the failure (e.g., "Could not process PDF", "Document empty", "Analysis error"). If "success" is true, this key can be omitted or null.

Provide ONLY the JSON object in your response."""


                request_content = [prompt, uploaded_file]
                safety_settings = [
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                ]
                response = model.generate_content(request_content, safety_settings=safety_settings)

                # --- 3. Process Response ---
                response_text = ""
                try:
                    if response.parts:
                        response_text = response.parts[0].text
                    else:
                         print("  Warning: Response might be empty or blocked.")
                         print(f"  Prompt Feedback: {response.prompt_feedback}")
                         raise ValueError("Response blocked or empty.") # Treat as failure

                    # Clean potential markdown fences
                    cleaned_text = response_text.strip()
                    if cleaned_text.startswith("```json"):
                        cleaned_text = cleaned_text[7:-3].strip() if cleaned_text.endswith("```") else cleaned_text[7:].strip()
                    elif cleaned_text.startswith("```"):
                         cleaned_text = cleaned_text[3:-3].strip() if cleaned_text.endswith("```") else cleaned_text[3:].strip()

                    # Parse JSON
                    result_json = json.loads(cleaned_text)

                    # Extract data using .get with defaults
                    analysis_result['success'] = result_json.get('success', False) # Default success to False if missing
                    analysis_result['rental_income'] = result_json.get('rental_income', '') # Default to blank string
                    analysis_result['tax_paid'] = result_json.get('tax_paid', '') # Default to blank string
                    analysis_result['reason'] = result_json.get('reason', '') # Default to blank string
                    analysis_result['rented_to_mp'] = result_json.get('rented_to_mp', '')
                    
                    # Ensure reason is populated if success is false but reason was omitted
                    if not analysis_result['success'] and not analysis_result['reason']:
                        analysis_result['reason'] = "Success was false but no reason provided by LLM."

                    print(f"    Rental Income: {analysis_result['rental_income']}")
                    print(f"    Tax Paid: {analysis_result['tax_paid']}")
                    print(f"    Rented To MP: {analysis_result['rented_to_mp']}") 
                    
                    if not analysis_result['success']:
                         print(f"    Failed - reason: {analysis_result['reason']}")

                except (json.JSONDecodeError, ValueError) as json_err: # Catch parse errors & explicit value error
                    print(f"  Error: Failed to parse Gemini response as JSON. {json_err}")
                    print(f"  Raw Response Text: {response_text[:500]}...") # Print snippet
                    analysis_result['success'] = False
                    analysis_result['reason'] = f"Failed to parse Gemini response: {json_err}"
                except Exception as parse_err:
                    print(f"  Error processing Gemini response: {parse_err}")
                    analysis_result['success'] = False
                    analysis_result['reason'] = f"Error processing response: {parse_err}"

                # --- 4. Calculate Tax Rate ---
                analysis_result['approx_tax_rate'] = calculate_tax_rate(
                    analysis_result['tax_paid'],
                    analysis_result['rental_income']
                )
                print(f"    Approx Tax Rate: {analysis_result['approx_tax_rate']}")


            except Exception as api_err:
                print(f"  Error interacting with Gemini API for unit {unit_number}: {api_err}")
                analysis_result['success'] = False
                analysis_result['reason'] = f"Gemini API Error: {api_err}"
                # Log details if possible
                if hasattr(api_err, 'response'):
                     print(f"  API Error details: {api_err.response}")

            finally:
                # --- 5. Clean up uploaded file ---
                if uploaded_file:
                    try:
                        # print(f"  Deleting uploaded file: {uploaded_file.name}...")
                        genai.delete_file(uploaded_file.name)
                        # print(f"  Successfully deleted file {uploaded_file.name}.") # Less verbose
                    except Exception as del_err:
                        print(f"  Warning: Could not delete uploaded file {uploaded_file.name}. Error: {del_err}")

            # --- 6. Write results to CSV ---
            # Ensure values are suitable for CSV (DictWriter handles basic types ok)
            # Convert None explicitly if necessary, though default is ''
            for key, value in analysis_result.items():
                if value is None:
                    analysis_result[key] = ''

            writer.writerow(analysis_result)
            outfile.flush() 
            # print(f"  Result written to {OUTPUT_CSV}")

            # Optional: Add a small delay between API calls to avoid rate limits
            # time.sleep(1) # Sleep for 1 second

        # End of loop through candidates_to_process

except IOError as e:
    print(f"\nError writing to output CSV file '{OUTPUT_CSV}': {e}")
except Exception as e:
    print(f"\nAn unexpected error occurred during the main processing loop: {e}")


# --- Final Summary ---
print(f"\nScript finished. Processed {current_count} units in this run.")
remaining = total_eligible_count - current_count
if remaining > 0:
    print(f"{remaining} eligible units remain to be processed.")
elif total_eligible_count > 0:
    print(f"All eligible units processed and outputed to {OUTPUT_CSV}.")
    print("Check through the list; if any errors were due to web failures then delete those lines and retry.")
    print("The script will search for missing items and add them to the output")
    